{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as  tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sys\n",
    "import os\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "epochs = 1000\n",
    "PATH_DATASET = '<path_to_dataset>'\n",
    "\n",
    "FILE_TRAIN = PATH_DATASET + \"SCALED_TRAINING_DATA.csv\"\n",
    "FILE_TEST  = PATH_DATASET + \"SCALED_TEST_DATA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES, numerical_features, categorical_features = [], [], []\n",
    "\n",
    "#read the columns\n",
    "CSV_COLUMN_NAMES = pd.read_csv(FILE_TRAIN, nrows=1).columns.tolist()\n",
    "train = pd.read_csv(FILE_TRAIN, names= CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(FILE_TEST, names= CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns we need\n",
    "COLUMNS_WE_AVOID = ['K_FILTER_START', 'Total_Run_(hrs)', 'Unnamed: 0']\n",
    "COLUMNS_WE_NEED = []\n",
    "\n",
    "for i in CSV_COLUMN_NAMES:\n",
    "\n",
    "\tif i not in COLUMNS_WE_AVOID:\n",
    "\t\tCOLUMNS_WE_NEED.append(i)\n",
    "\n",
    "FEATURES = COLUMNS_WE_NEED[:-1]\n",
    "LABEL = COLUMNS_WE_NEED.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now set the X_trian, X_test\n",
    "train_x, train_y = train[FEATURES], train[LABEL]\n",
    "test_x, test_y = test[FEATURES], test[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Features:(338, 52)\n",
      "Label Output:(338,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Features:{}\".format(train_x.shape))\n",
    "print(\"Label Output:{}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input Features:(41, 52)\n",
      "Test Label Output:(41,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Input Features:{}\".format(test_x.shape))\n",
    "print(\"Test Label Output:{}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the column type and store them in an array\n",
    "for column in train_x.columns:\n",
    "\t#write conditions here\n",
    "\tif (train_x[column].dtype == np.float64 or train_x[column].dtype == np.int64):\n",
    "\t\tnumerical_features.append(column) #append to the numerical features\n",
    "\telse:\n",
    "\t\tcategorical_features.append(column) #append to the categorical features\n",
    "        \n",
    "#building feature columns\n",
    "feature_columns = [tf.feature_column.numeric_column(k) for k in numerical_features]\n",
    "\n",
    "#get the unique key values for the categorical variable\n",
    "for k in categorical_features:\n",
    "\t#get the unique values\n",
    "\tcurrent_bucket = train_x[k].nunique()\n",
    "\tif current_bucket > 10:\n",
    "\t\tfeature_columns.append(\n",
    "\t\t\ttf.feature_column.indicator_column(\n",
    "\t\t\t\ttf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\t\t\t\t\tkey = k,\n",
    "\t\t\t\t\tvocabulary_list = train_x[k].unique()\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\telse:\n",
    "\t\tfeature_columns.append(\n",
    "\t\t\ttf.feature_column.indicator_column(\n",
    "\t\t\t\t# for columns that we want the the library to automatically map values for us\n",
    "\t\t\t\ttf.feature_column.categorical_column_with_hash_bucket(\n",
    "\t\t\t\t\tkey=k,\n",
    "\t\t\t\t\tvocabulary_list = train[k].unique()\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size, epochs):\n",
    "\t#Slice the tensor into single type.\n",
    "\t#for eg: <name=Tensor0, Shape=(?,1)>\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\tdataset = dataset.shuffle(256).repeat(epochs).batch(batch_size)\n",
    "\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "\t#get features as dictionary\n",
    "\tfeatures = dict(features)\n",
    "\t#if labels are none\n",
    "\tif labels is None:\n",
    "\t\tprint(\"Entered into the loop because Label is None\")\n",
    "\t\tinputs = features\n",
    "\n",
    "\t#if there is label, map the input features with labels \n",
    "\telse:\n",
    "\t\tinputs = (features, labels)\n",
    "\n",
    "\t#convert into tensors\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\tassert batch_size is not None, \"BATCH SIZE MUST NOT BE NONE\"\n",
    "\t#split the batchsize\n",
    "\tdataset = dataset.batch(batch_size)\n",
    "\t#return the dataset\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(features, labels, mode, params):\n",
    "\n",
    "\tif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\t\ttf.logging.info(\"My_Model_Fn: PREDICT, {}\".format(mode))\n",
    "\telif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\t\ttf.logging.info(\"My_Model_Fn: EVAL, {}\".format(mode))\n",
    "\telif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\t\ttf.logging.info(\"My_Model_Fn: TRAIN, {}\".format(mode))\n",
    "\n",
    "\t#setup the initializer\n",
    "\tinitializer = tf.contrib.layers.xavier_initializer()\n",
    "\tregularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "\n",
    "\tinput_layer = tf.feature_column.input_layer(features, feature_columns)\n",
    "\th1 = tf.layers.Dense(100, activation=tf.nn.relu,\n",
    "\t\t\t\t\t\t\t\tkernel_regularizer= regularizer,\n",
    "\t\t\t\t\t\t\t\tkernel_initializer= initializer)(input_layer)\n",
    "\n",
    "\th2 = tf.layers.Dense(80, activation=tf.nn.relu,\n",
    "\t\t\t\t\t\t\t\tkernel_regularizer= regularizer,\n",
    "\t\t\t\t\t\t\t\tkernel_initializer= initializer)(h1)\n",
    "\n",
    "\th3 = tf.layers.Dense(80, activation=tf.nn.relu,\n",
    "\t\t\t\t\t\t\t\tkernel_regularizer= regularizer,\n",
    "\t\t\t\t\t\t\t\tkernel_initializer= initializer)(h2)\n",
    "\n",
    "\tlogits = tf.layers.Dense(2)(h3)\n",
    "\n",
    "\t#compute predictions\n",
    "\tpredicted_classes = tf.argmax(input= logits, axis=1)\n",
    "\tif mode == tf.estimator. ModeKeys.PREDICT:\n",
    "\t\tpredictions = {\n",
    "\t\t\t'class_ids': predicted_classes[:, tf.newaxis],\n",
    "\t\t\t'probabilites': tf.nn.softmax(logits),\n",
    "\t\t\t'logits': logits\n",
    "\t\t}\n",
    "\n",
    "\t\treturn tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "\n",
    "\tloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "\taccuracy = tf.metrics.accuracy(labels= labels, predictions=predicted_classes, name='acc_op')\n",
    "\tprecision = tf.metrics.precision(labels, predictions= predicted_classes, name='precision_op')\n",
    "\trecall = tf.metrics.recall(labels, predictions= predicted_classes, name='recall_op')\n",
    "\tauc = tf.metrics.auc(labels, predictions=predicted_classes, name='auc_op')\n",
    "\n",
    "\tmetrics = {\n",
    "\t\t'accuracy': accuracy,\n",
    "\t\t'precision': precision,\n",
    "\t\t'recall': recall,\n",
    "\t\t'auc': auc\n",
    "\t}\n",
    "\n",
    "\ttf.summary.scalar('my_accuracy', accuracy[1])\n",
    "\ttf.summary.scalar('my_precision', precision[1])\n",
    "\ttf.summary.scalar('my_recall', recall[1])\n",
    "\ttf.summary.scalar('my_auc', auc[1])\n",
    "\n",
    "\tif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "\t\treturn tf.estimator.EstimatorSpec(\n",
    "\t\t\tmode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "\t#training_op\n",
    "\tassert mode == tf.estimator.ModeKeys.TRAIN, \"Train is the only Mode Key\"\n",
    "\toptimizer = tf.train.AdagradOptimizer(learning_rate=0.0001)\n",
    "\ttrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "\tgrads = optimizer.compute_gradients(loss)\n",
    "\n",
    "\tfor grad, var in grads:\n",
    "\t\tif grad is not None:\n",
    "\t\t\ttf.summary.histogram(var.op.name + \"/gradients\", grad)\n",
    "\n",
    "\tfor var in tf.trainable_variables():\n",
    "\t\ttf.summary.histogram(var.name, var)\n",
    "\n",
    "\n",
    "\treturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "   \n",
    "    for i in FEATURES:\n",
    "        feature_placeholders.update({i:tf.placeholder(tf.float32, [None])})\n",
    "\n",
    "    \n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_service': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014396F34240>, '_device_fn': None, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_log_step_count_steps': 100, '_master': '', '_num_ps_replicas': 0, '_train_distribute': None, '_num_worker_replicas': 1, '_evaluation_master': '', '_model_dir': 'C:\\\\Users\\\\MADHIV~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9ppav3cz'}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function my_model_fn at 0x0000014396EF5C80>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:My_Model_Fn: TRAIN, train\n",
      "INFO:tensorflow:Summary name dense/kernel:0 is illegal; using dense/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense/bias:0 is illegal; using dense/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/kernel:0 is illegal; using dense_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/bias:0 is illegal; using dense_3/bias_0 instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.5564131, step = 0\n",
      "INFO:tensorflow:global_step/sec: 61.0781\n",
      "INFO:tensorflow:loss = 0.504238, step = 100 (1.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.243\n",
      "INFO:tensorflow:loss = 0.39530858, step = 200 (0.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.274\n",
      "INFO:tensorflow:loss = 0.3910915, step = 300 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.039\n",
      "INFO:tensorflow:loss = 0.34605473, step = 400 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.353\n",
      "INFO:tensorflow:loss = 0.31329358, step = 500 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.801\n",
      "INFO:tensorflow:loss = 0.41533795, step = 600 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.091\n",
      "INFO:tensorflow:loss = 0.4886507, step = 700 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.758\n",
      "INFO:tensorflow:loss = 0.3798587, step = 800 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.71\n",
      "INFO:tensorflow:loss = 0.35207832, step = 900 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.059\n",
      "INFO:tensorflow:loss = 0.26280016, step = 1000 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.166\n",
      "INFO:tensorflow:loss = 0.43912724, step = 1100 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.873\n",
      "INFO:tensorflow:loss = 0.37088156, step = 1200 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.201\n",
      "INFO:tensorflow:loss = 0.20821004, step = 1300 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.538\n",
      "INFO:tensorflow:loss = 0.2626884, step = 1400 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.078\n",
      "INFO:tensorflow:loss = 0.23725313, step = 1500 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.968\n",
      "INFO:tensorflow:loss = 0.33999592, step = 1600 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.522\n",
      "INFO:tensorflow:loss = 0.28095663, step = 1700 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.943\n",
      "INFO:tensorflow:loss = 0.2773474, step = 1800 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.348\n",
      "INFO:tensorflow:loss = 0.41687894, step = 1900 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.459\n",
      "INFO:tensorflow:loss = 0.21724656, step = 2000 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.747\n",
      "INFO:tensorflow:loss = 0.31573492, step = 2100 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.868\n",
      "INFO:tensorflow:loss = 0.4156313, step = 2200 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.801\n",
      "INFO:tensorflow:loss = 0.2778018, step = 2300 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.294\n",
      "INFO:tensorflow:loss = 0.28717703, step = 2400 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.575\n",
      "INFO:tensorflow:loss = 0.16747186, step = 2500 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.745\n",
      "INFO:tensorflow:loss = 0.25814924, step = 2600 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.481\n",
      "INFO:tensorflow:loss = 0.22489794, step = 2700 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.289\n",
      "INFO:tensorflow:loss = 0.26205865, step = 2800 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.471\n",
      "INFO:tensorflow:loss = 0.26422295, step = 2900 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.814\n",
      "INFO:tensorflow:loss = 0.14885232, step = 3000 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.049\n",
      "INFO:tensorflow:loss = 0.21870905, step = 3100 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.076\n",
      "INFO:tensorflow:loss = 0.13421409, step = 3200 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.827\n",
      "INFO:tensorflow:loss = 0.18737446, step = 3300 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.117\n",
      "INFO:tensorflow:loss = 0.45580304, step = 3400 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.301\n",
      "INFO:tensorflow:loss = 0.2690254, step = 3500 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.638\n",
      "INFO:tensorflow:loss = 0.35566872, step = 3600 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.639\n",
      "INFO:tensorflow:loss = 0.18565676, step = 3700 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.907\n",
      "INFO:tensorflow:loss = 0.2931344, step = 3800 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.798\n",
      "INFO:tensorflow:loss = 0.14301643, step = 3900 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.907\n",
      "INFO:tensorflow:loss = 0.33440793, step = 4000 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.08\n",
      "INFO:tensorflow:loss = 0.29979557, step = 4100 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.619\n",
      "INFO:tensorflow:loss = 0.1686154, step = 4200 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.779\n",
      "INFO:tensorflow:loss = 0.17146197, step = 4300 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.921\n",
      "INFO:tensorflow:loss = 0.2012075, step = 4400 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.497\n",
      "INFO:tensorflow:loss = 0.25048846, step = 4500 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.906\n",
      "INFO:tensorflow:loss = 0.16816404, step = 4600 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.881\n",
      "INFO:tensorflow:loss = 0.3524291, step = 4700 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.447\n",
      "INFO:tensorflow:loss = 0.16702433, step = 4800 (0.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.964\n",
      "INFO:tensorflow:loss = 0.26662338, step = 4900 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.745\n",
      "INFO:tensorflow:loss = 0.32811135, step = 5000 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.556\n",
      "INFO:tensorflow:loss = 0.25731665, step = 5100 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.439\n",
      "INFO:tensorflow:loss = 0.44996423, step = 5200 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.423\n",
      "INFO:tensorflow:loss = 0.2144846, step = 5300 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.707\n",
      "INFO:tensorflow:loss = 0.35471764, step = 5400 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.506\n",
      "INFO:tensorflow:loss = 0.25144362, step = 5500 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.578\n",
      "INFO:tensorflow:loss = 0.24175364, step = 5600 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.546\n",
      "INFO:tensorflow:loss = 0.14659145, step = 5700 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.203\n",
      "INFO:tensorflow:loss = 0.15284391, step = 5800 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.382\n",
      "INFO:tensorflow:loss = 0.20498303, step = 5900 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.646\n",
      "INFO:tensorflow:loss = 0.14831507, step = 6000 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.369\n",
      "INFO:tensorflow:loss = 0.16512378, step = 6100 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2672584, step = 6200 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.69\n",
      "INFO:tensorflow:loss = 0.12525794, step = 6300 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.898\n",
      "INFO:tensorflow:loss = 0.2827819, step = 6400 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.413\n",
      "INFO:tensorflow:loss = 0.20719725, step = 6500 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.051\n",
      "INFO:tensorflow:loss = 0.19833869, step = 6600 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.095\n",
      "INFO:tensorflow:loss = 0.10445, step = 6700 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.403\n",
      "INFO:tensorflow:loss = 0.17371762, step = 6800 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.973\n",
      "INFO:tensorflow:loss = 0.23528865, step = 6900 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.245\n",
      "INFO:tensorflow:loss = 0.27854252, step = 7000 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.665\n",
      "INFO:tensorflow:loss = 0.13983281, step = 7100 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.368\n",
      "INFO:tensorflow:loss = 0.22992522, step = 7200 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.261\n",
      "INFO:tensorflow:loss = 0.40514234, step = 7300 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.852\n",
      "INFO:tensorflow:loss = 0.17868528, step = 7400 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.132\n",
      "INFO:tensorflow:loss = 0.21725914, step = 7500 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.738\n",
      "INFO:tensorflow:loss = 0.16771284, step = 7600 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.24\n",
      "INFO:tensorflow:loss = 0.08342648, step = 7700 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.043\n",
      "INFO:tensorflow:loss = 0.13878846, step = 7800 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.902\n",
      "INFO:tensorflow:loss = 0.13190132, step = 7900 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.5\n",
      "INFO:tensorflow:loss = 0.16612644, step = 8000 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.328\n",
      "INFO:tensorflow:loss = 0.13269112, step = 8100 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.67\n",
      "INFO:tensorflow:loss = 0.21500307, step = 8200 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.78\n",
      "INFO:tensorflow:loss = 0.24335128, step = 8300 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.548\n",
      "INFO:tensorflow:loss = 0.15644497, step = 8400 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.987\n",
      "INFO:tensorflow:loss = 0.1319606, step = 8500 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.139\n",
      "INFO:tensorflow:loss = 0.25128108, step = 8600 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.043\n",
      "INFO:tensorflow:loss = 0.276159, step = 8700 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.664\n",
      "INFO:tensorflow:loss = 0.42827088, step = 8800 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.775\n",
      "INFO:tensorflow:loss = 0.33918238, step = 8900 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.864\n",
      "INFO:tensorflow:loss = 0.22664148, step = 9000 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.887\n",
      "INFO:tensorflow:loss = 0.32702345, step = 9100 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.212\n",
      "INFO:tensorflow:loss = 0.24313407, step = 9200 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.016\n",
      "INFO:tensorflow:loss = 0.18830773, step = 9300 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.31\n",
      "INFO:tensorflow:loss = 0.23515786, step = 9400 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.253\n",
      "INFO:tensorflow:loss = 0.13188028, step = 9500 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.294\n",
      "INFO:tensorflow:loss = 0.10757679, step = 9600 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.618\n",
      "INFO:tensorflow:loss = 0.17700957, step = 9700 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.059\n",
      "INFO:tensorflow:loss = 0.19369063, step = 9800 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.36\n",
      "INFO:tensorflow:loss = 0.2409837, step = 9900 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.809\n",
      "INFO:tensorflow:loss = 0.18189806, step = 10000 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.407\n",
      "INFO:tensorflow:loss = 0.33476987, step = 10100 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.136\n",
      "INFO:tensorflow:loss = 0.25063318, step = 10200 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.289\n",
      "INFO:tensorflow:loss = 0.16818431, step = 10300 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.931\n",
      "INFO:tensorflow:loss = 0.27597922, step = 10400 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.308\n",
      "INFO:tensorflow:loss = 0.10998796, step = 10500 (0.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10563 into C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.22096029.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x14396f34400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"<dir_to_save_tensorflow_model>\"\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "\tmodel_fn = my_model_fn\n",
    ")\n",
    "\n",
    "classifier.train(input_fn=lambda: train_input_fn(train_x, train_y, BATCH_SIZE, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:My_Model_Fn: EVAL, eval\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-16-06:19:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\\model.ckpt-10563\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-16-06:19:46\n",
      "INFO:tensorflow:Saving dict for global step 10563: accuracy = 0.85365856, auc = 0.4999999, global_step = 10563, loss = 0.68403476, precision = 0.85365856, recall = 1.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10563: C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\\model.ckpt-10563\n",
      "Evaluation Results:\n",
      "---------------------------------------------------------------------------\n",
      " precision, was:0.8536585569381714\n",
      " global_step, was:10563\n",
      " loss, was:0.6840347647666931\n",
      " accuracy, was:0.8536585569381714\n",
      " auc, was:0.49999991059303284\n",
      " recall, was:1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_result = classifier.evaluate(input_fn=lambda: eval_input_fn(test_x, test_y, BATCH_SIZE))\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for key in evaluate_result:\n",
    "\tprint(\" {}, was:{}\".format(key, evaluate_result[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {k:list() for k in FEATURES}\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    for ind,f in enumerate(FEATURES):\n",
    "        value = test_x.iloc[i][ind]\n",
    "        predictions[f].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(predictions, None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered into the loop because Label is None\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:My_Model_Fn: PREDICT, infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp9ppav3cz\\model.ckpt-10563\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = [p for p in model_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:0\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:0\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:0\n",
      "Expeceted:1, Predicted:0\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:0\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:1\n",
      "Expeceted:1, Predicted:0\n"
     ]
    }
   ],
   "source": [
    "CLASS = [0,1]\n",
    "predicted_class = None\n",
    "\n",
    "#iterate through the list to get the predictions and expected value\n",
    "for ind, i in enumerate(predicted_classes):\n",
    "    #type(i) => Dictionary\n",
    "    probabilities = i['probabilites']\n",
    "    \n",
    "    if probabilities[0] > probabilities[1]:\n",
    "        predicted_class = 0\n",
    "    else:\n",
    "        predicted_class = 1\n",
    "    \n",
    "    print(\"Expeceted:{}, Predicted:{}\".format(predicted_class, test_y[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reason for Not Predicting Class 0 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is Unbalanced, Total Rows 339, out of 339 rows only 18 rows labeled as 0 which 18% of data. Since the model is trained in this low data, the model is not so good at predicting the label 0. To overcome this particular problem, we can use several method like\n",
    "    1. Oversampling/Undersampling\n",
    "    2. Populating more data for label 0\n",
    "    3. Use K-Fold Cross Validation Method\n",
    "    4. Get more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Some Decision Tree Classifiers ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=2, random_state=0)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.24439293e-03 1.77015210e-02 2.74101260e-02 8.60526108e-03\n",
      " 2.65353905e-02 1.46965984e-02 3.58506740e-02 2.08987678e-02\n",
      " 8.51453369e-03 1.01746224e-02 2.39648139e-02 6.19670288e-02\n",
      " 1.24881699e-02 1.83819942e-02 2.13309071e-02 1.67789670e-02\n",
      " 1.18760066e-02 9.64939995e-03 4.57632035e-03 5.14327974e-03\n",
      " 1.49941518e-02 1.30568677e-02 1.55982537e-02 1.98518692e-02\n",
      " 1.36288176e-02 1.28029028e-02 1.58866329e-01 1.01054850e-02\n",
      " 6.13662362e-03 1.46939099e-02 1.75909760e-02 7.62561865e-03\n",
      " 4.46433238e-02 1.41530407e-02 2.31983210e-02 2.06695071e-02\n",
      " 4.56574686e-03 1.06360815e-01 0.00000000e+00 0.00000000e+00\n",
      " 1.59806125e-02 0.00000000e+00 0.00000000e+00 7.94780986e-03\n",
      " 1.34028552e-04 2.33884800e-03 0.00000000e+00 9.02912658e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.94933532e-05 1.95660726e-03]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822485207100592"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(kernel='linear', C = 1.0)\n",
    "model.fit(train_x, train_y)\n",
    "model.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:0, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:0, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:0, predicted:1\n",
      "Expected:0, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:0, predicted:0\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:1, predicted:1\n",
      "Expected:0, predicted:1\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(test_x)\n",
    "\n",
    "for ind,i in enumerate(test_y):\n",
    "    print(\"Expected:{}, predicted:{}\".format(i, predicted[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems the above model works well than previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5]\n",
      " [ 0 35]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.17      0.29         6\n",
      "          1       0.88      1.00      0.93        35\n",
      "\n",
      "avg / total       0.89      0.88      0.84        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "print(confusion_matrix(test_y,predicted))  \n",
    "print(classification_report(test_y, predicted))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
